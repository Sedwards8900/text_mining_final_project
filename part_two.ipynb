{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install google\n",
    "!pip3 install us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# installing libraries required to run program through os library by running it in terminal/console\n",
    "os.system('pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for program\n",
    "\n",
    "# To gather data for US States\n",
    "import us\n",
    "\n",
    "# To perform search query, navigate and extract links, and download data from each link obtained\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import requests as r\n",
    "\n",
    "import re\n",
    "import json\n",
    "from os import path\n",
    " \n",
    "# k-means algorithm to create clusters\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the visible web results from google search\n",
    "def googleSearch(user_agents:str, q:str, num_pages:int):    \n",
    "    # Set headers\n",
    "    headers = {\n",
    "        'User-Agent': user_agents}\n",
    "    print(headers['User-Agent'])\n",
    "    q = '+'.join(q.split())\n",
    "    url = f'https://www.google.com/search?q={q}&num={num_pages}'\n",
    "    response = r.get(url) # Changes output of class and id names\n",
    "    response = r.get(url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "    temp = soup.find_all('a', href=True)\n",
    "\n",
    "    sub_s = '/url?q=' # if User-Agent not set, this is going to show up at front of url\n",
    "    # links = [a['href'].replace(sub_s, '') for a in temp if sub_s in a['href'] and 'google' not in a['href']] # Use if no headers\n",
    "    links = [a['href'].replace(sub_s, '') for a in temp if ('https' in a['href'] or 'http' in a['href']) and 'google' not in a['href'] and 'search' not in a['href']]\n",
    "    print('links: ', links)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each of the links into a text file\n",
    "def write_links(results:list, state:str):\n",
    "    with open('links.txt', 'a') as f:\n",
    "        for items in results:\n",
    "            f.write('%s\\n' %items)\n",
    "        print(f'{state} links written successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info on all states\n",
    "us_states = [state.name for state in us.states.STATES]\n",
    "# Main query variable\n",
    "query = \"storm article\"\n",
    "# Storage dictionary for all states\n",
    "all_links = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Example individual function call\n",
    "user_agent = random.randint(0,7)\n",
    "print(user_agent)\n",
    "# result = googleSearch('georgia storm article', 100)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Alabama links written successfully\n",
      "[]\n",
      "Alaska links written successfully\n",
      "[]\n",
      "Arizona links written successfully\n"
     ]
    }
   ],
   "source": [
    "# Loop through each state to gather website links\n",
    "for state in us_states[:3]:\n",
    "    # Create query with state name\n",
    "    st_query = state + ' ' + query\n",
    "    \n",
    "    # Set up list on dictionary for each state\n",
    "    all_links[state] = googleSearch(st_query, 100)\n",
    "    print(all_links[state])\n",
    "    write_links(all_links[state], state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': [],\n",
       " 'Alaska': [],\n",
       " 'Arizona': [],\n",
       " 'Arkansas': [],\n",
       " 'California': [],\n",
       " 'Colorado': [],\n",
       " 'Connecticut': [],\n",
       " 'Delaware': [],\n",
       " 'Florida': [],\n",
       " 'Georgia': [],\n",
       " 'Hawaii': [],\n",
       " 'Idaho': [],\n",
       " 'Illinois': [],\n",
       " 'Indiana': [],\n",
       " 'Iowa': [],\n",
       " 'Kansas': [],\n",
       " 'Kentucky': [],\n",
       " 'Louisiana': [],\n",
       " 'Maine': [],\n",
       " 'Maryland': [],\n",
       " 'Massachusetts': [],\n",
       " 'Michigan': [],\n",
       " 'Minnesota': [],\n",
       " 'Mississippi': [],\n",
       " 'Missouri': [],\n",
       " 'Montana': [],\n",
       " 'Nebraska': [],\n",
       " 'Nevada': [],\n",
       " 'New Hampshire': [],\n",
       " 'New Jersey': [],\n",
       " 'New Mexico': [],\n",
       " 'New York': [],\n",
       " 'North Carolina': [],\n",
       " 'North Dakota': [],\n",
       " 'Ohio': [],\n",
       " 'Oklahoma': [],\n",
       " 'Oregon': [],\n",
       " 'Pennsylvania': [],\n",
       " 'Rhode Island': [],\n",
       " 'South Carolina': [],\n",
       " 'South Dakota': [],\n",
       " 'Tennessee': [],\n",
       " 'Texas': [],\n",
       " 'Utah': [],\n",
       " 'Vermont': [],\n",
       " 'Virginia': [],\n",
       " 'Washington': [],\n",
       " 'West Virginia': [],\n",
       " 'Wisconsin': [],\n",
       " 'Wyoming': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length of dictionary, should be 50\n",
    "len(all_links)\n",
    "all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download HTMLs\n",
    "def html_downloader(filename:str):\n",
    "\n",
    "    # Open data from txt file\n",
    "    links = open(filename, 'r')\n",
    "    count = 0\n",
    "    # Loop through each line of the text file\n",
    "    for line in links:\n",
    "        # Extract html from the internet\n",
    "        file = r.get(line.strip())\n",
    "\n",
    "        # Check if request worked, if not, print warning, if yes, create downloaded data into html\n",
    "        if file.status_code == 404:\n",
    "            print(file.status_code, \"Unable to extract html for \", line)\n",
    "        else:\n",
    "            linet = line.strip().replace(\"https://en.wikipedia.org/wiki/\",\"\").replace(\"/\",\"and\")\n",
    "            open(f'./Wikipedia articles on common diseases/{linet}.html', 'wb').write(file.content)\n",
    "  \n",
    "    # Close txt file\n",
    "    links.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the number of k clusters to 25\n",
    "num_clusters = 25\n",
    "\n",
    "''' \n",
    "Call function to create clusters\n",
    "Params:     n_clusters = number of desired clusters\n",
    "            random_state = control level of randomness\n",
    "'''\n",
    "kmeans_doc = KMeans(n_clusters=num_clusters, random_state=42).fit(doc_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
